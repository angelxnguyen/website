---
title: "Project 2"
author: "Tien Nguyen TN7898"
date: "11/25/2019"
output: html_document
---



<p>###Introduction:</p>
<p><em>In this project, I will be modeling, testing, and making predictions on a dataset created from observations on the game, <strong>World of Warcraft</strong>, which is a MMORPG created by <strong>Blizzard</strong>. This dataset contains information about battlegrounds, which are timed matches in an instanced area where players are able to compete against other players (PvP). Players are placed in teams on the basis of the faction that they belong to, the Alliance or the Horde, and their character’s level, so the matches consist of similar team compositions competing against one another. At the end of each battleground, there is a summary containing information for each of the players for both factions. I will be specifically looking at the numeric variables: <strong>Damage done, Healing done, Honorable kills, and Honor awarded</strong> and the categorical variable: <strong>Faction and Win</strong>.</em></p>
<hr />
<p>###Data Preparation:</p>
<p><em>I will be preloading all of the packages I will be using in this project. Additionally, to prepare the data and make it easier to understand, I renamed the abbreviations in the columns with their full names.</em></p>
<pre class="r"><code># Loading packages
library(ggplot2)
library(dplyr)
library(sandwich)
library(lmtest)
library(tidyverse)
library(MASS)
library(plotROC)
library(glmnet)

# Loading data
wowdata &lt;- read.csv(&quot;C:/users/njare/Desktop/website/content/wowbgs.csv&quot;)
colnames(wowdata) &lt;- c(&quot;Battleground&quot;, &quot;Code&quot;, &quot;Faction&quot;, &quot;Class&quot;, 
    &quot;Num_mortal_kills&quot;, &quot;Num_deaths&quot;, &quot;Honorable_kills&quot;, &quot;Damage_done&quot;, 
    &quot;Healing_done&quot;, &quot;Honor_awarded&quot;, &quot;Win&quot;, &quot;Lose&quot;, &quot;Class_speciality&quot;, 
    &quot;Bonus_event&quot;)</code></pre>
<hr />
<p>###Performing a MANOVA Test:</p>
<p><em>I want to simultaneously determine whether Damage done, Healing done, and Honor awarded differ by Faction. I am doing this because I want to see if there is a difference in perfomance based on a player’s Faction. If the MANOVA results in significant findings, ANOVA tests and post hoc tests will be ran to determine where the significance lies in the dependent variables.</em></p>
<p><em><strong>My hypotheses for my MANOVA test:</strong></em></p>
<p><em>Null Hypothesis: For each of the dependent variables (Damage done, Healing done, and Honor awarded), the means of each Faction are equal.</em></p>
<p><em>Alternative Hypothesis: For at least one dependent variable (Damage done, Healing done, and Honor awarded), at least one Faction mean is different.</em></p>
<pre class="r"><code># Eyeball testing the assumption for homogeneity of
# covariances.
covmats &lt;- wowdata %&gt;% group_by(Faction) %&gt;% do(covs = cov(.[8:10]))
for (i in 1:3) {
    print(covmats$covs[i])
}</code></pre>
<pre><code>## [[1]]
##               Damage_done Healing_done Honor_awarded
## Damage_done    1137010635   -246754185    2214139.84
## Healing_done   -246754185   1359828872    1265024.80
## Honor_awarded     2214140      1265025      58691.48
## 
## [[1]]
##                Damage_done Healing_done Honor_awarded
## Damage_done   1067379612.5 -274344587.6     418411.35
## Healing_done  -274344587.6 1461176277.8     291982.05
## Honor_awarded     418411.3     291982.1      25834.97
## 
## [[1]]
## NULL</code></pre>
<pre class="r"><code>man &lt;- manova(cbind(Damage_done, Healing_done, Honor_awarded) ~ 
    Faction, data = wowdata)
summary(man)  #Signigicant results.</code></pre>
<pre><code>##             Df    Pillai approx F num Df den Df    Pr(&gt;F)    
## Faction      1 0.0070078   8.7557      3   3722 8.751e-06 ***
## Residuals 3724                                               
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>summary.aov(man)  #Healing done and Honor awarded have significant results.</code></pre>
<pre><code>##  Response Damage_done :
##               Df     Sum Sq    Mean Sq F value Pr(&gt;F)
## Faction        1 4.7602e+08  476017861   0.432 0.5111
## Residuals   3724 4.1037e+12 1101970749               
## 
##  Response Healing_done :
##               Df     Sum Sq    Mean Sq F value  Pr(&gt;F)  
## Faction        1 7.7734e+09 7773373460  5.5098 0.01896 *
## Residuals   3724 5.2539e+12 1410829151                  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
##  Response Honor_awarded :
##               Df    Sum Sq Mean Sq F value    Pr(&gt;F)    
## Faction        1    603290  603290   14.31 0.0001574 ***
## Residuals   3724 156993972   42157                      
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>pairwise.t.test(wowdata$Healing_done, wowdata$Faction, p.adj = &quot;none&quot;)</code></pre>
<pre><code>## 
##  Pairwise comparisons using t tests with pooled SD 
## 
## data:  wowdata$Healing_done and wowdata$Faction 
## 
##       Alliance
## Horde 0.019   
## 
## P value adjustment method: none</code></pre>
<pre class="r"><code>pairwise.t.test(wowdata$Honor_awarded, wowdata$Faction, p.adj = &quot;none&quot;)</code></pre>
<pre><code>## 
##  Pairwise comparisons using t tests with pooled SD 
## 
## data:  wowdata$Honor_awarded and wowdata$Faction 
## 
##       Alliance
## Horde 0.00016 
## 
## P value adjustment method: none</code></pre>
<pre class="r"><code>1 - (0.95^6)  #Probability of at least one type I error = 0.2649081.</code></pre>
<pre><code>## [1] 0.2649081</code></pre>
<pre class="r"><code>0.05/6  #Corrected significance level = 0.008333333.</code></pre>
<pre><code>## [1] 0.008333333</code></pre>
<p><em>There are 6 assumptions for a MANOVA test and because there are so many it is difficult to entirely test or meet all of them; however, most of them can be assumed to be met for this dataset. The samples were random and independent of one another, there are no extreme univariate or multivariate outliers because those players can only be underperformers, which are generally removed from matches within a minute of being idle, so their data will not be included at the end. The dependent variables were not found to be too correlated to one another. Multivariate assumptions normality and homogeneity of covariances can be eyeballed and found to be met for the most part. For the ANOVA tests, all of the assumptions were found to be met. The sample was large and random and contained independent samples. Additionally, the equal variance assumption can be assumed to have been met.</em></p>
<p><em>A MANOVA was conducted in order to determine the effect of Faction (Alliance and Horde) on three dependent variables (Damage done, Healing done, and Honor awarded). Significant differences were found among the two factions on the three dependent measures (Pillai trace = 0.007, pseudo F (3, 3722) = 8.7557, p-value = 0.751e-06). With this, we are able to reject the null hypothesis. ANOVA tests for each variable were performed in order to determine which of dependent variables were significant. The univariate ANOVAs for Healing done and Honor awarded were found to be significant (F(1,3724) = 5.5098, p-value = 0.01896 and F(1, 3724) = 14.31, p-value = 0.0001574), respectively. The Bonferroni method for controlling Type I error rates for multiple comparisons was used, and the probability of at least one Type I error from performing 6 tests was found to be 26.49%. Post hoc tests were then performed and the results were all significant when compared to an alpha level of 0.05; however, because 6 tests were performed, an adjusted alpha level of 0.00833 will be used to conclude these post hoc tests. In conclusion, only Honor awarded significantly differed between the Alliance and the Horde.</em></p>
<hr />
<div id="performing-a-randomization-test" class="section level3">
<h3>Performing a Randomization Test:</h3>
<p><em>The randomization test that I will be performing will be a two-tailed t-test. I want to determine whether the two factions yield the same total healing done on average in a battleground.</em></p>
<p><em><strong>My hypotheses for my two-tailed t-test:</strong></em></p>
<p><em>Null Hypothesis: The total average healing done in a battleground will not differ between the two factions (Alliance and Horde).</em></p>
<p><em>Alternative Hypothesis: The total average healing done in a battleground does differ between the two factions (Alliance and Horde).</em></p>
<pre class="r"><code># Preparing the data
wowdata &lt;- wowdata %&gt;% mutate(Faction = ifelse(Faction == &quot;Alliance&quot;, 
    1, 0))

t.test(data = wowdata, Healing_done ~ Faction)</code></pre>
<pre><code>## 
##  Welch Two Sample t-test
## 
## data:  Healing_done by Faction
## t = 2.3478, df = 3722, p-value = 0.01893
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##   476.4641 5301.2007
## sample estimates:
## mean in group 0 mean in group 1 
##        27861.80        24972.97</code></pre>
<pre class="r"><code>heal &lt;- wowdata %&gt;% dplyr::select(3, 9)
heal %&gt;% dplyr::group_by(Faction) %&gt;% dplyr::summarise(means = mean(Healing_done)) %&gt;% 
    dplyr::summarize(`mean_diff:` = diff(means))</code></pre>
<pre><code>## # A tibble: 1 x 1
##   `mean_diff:`
##          &lt;dbl&gt;
## 1       -2889.</code></pre>
<pre class="r"><code>rand_dist &lt;- vector()
for (i in 1:5000) {
    new &lt;- data.frame(Healing_done = sample(heal$Healing_done), 
        Faction = heal$Faction)
    rand_dist[i] &lt;- mean(new[new$Faction == &quot;1&quot;, ]$Healing_done) - 
        mean(new[new$Faction == &quot;0&quot;, ]$Healing_done)
}

mean(rand_dist &gt; 2888.832) * 2</code></pre>
<pre><code>## [1] 0.014</code></pre>
<pre class="r"><code># Graphing
{
    hist(rand_dist, main = &quot;&quot;, ylab = &quot;&quot;)
    abline(v = 2888.832, col = &quot;red&quot;)
}</code></pre>
<p><img src="/project2_files/figure-html/unnamed-chunk-3-1.png" width="768" style="display: block; margin: auto;" /></p>
<pre class="r"><code>data.frame(rand_dist) %&gt;% ggplot(aes(rand_dist)) + geom_histogram(aes(y = ..density..), 
    bins = 30) + stat_function(fun = dt, geom = &quot;line&quot;)</code></pre>
<p><img src="/project2_files/figure-html/unnamed-chunk-3-2.png" width="768" style="display: block; margin: auto;" /></p>
<p><em>A two-tailed t-test was performed and a p-value of 0.01893 was obtained. The two factions do not yield the same healing done on average per battleground; the Alliance had an average healing done total of 24972.97 and the Horde had an average healing done total of 27861.80, revealing that the Horde generally yield more healing done per battleground. When generating a random distribution of 5000 mean differences on randomized data using a loop for the original healing done data, the two-tailed p-value came out to be 0.0188, which gives me the same conclusion as the parametric t-test done prior, that the mean healing done totals differ between the Alliance and the Horde.</em></p>
<hr />
<p>###Building a Multiple Regression Model:</p>
<p><em>I will be building a model that will allow me to predict how much Honor is awarded to the player based on their Faction and Honorable kills. The variable Honorable kills will be mean centered because it is a numeric variable and mean centering it will allow for more meaningful interpretation.</em></p>
<pre class="r"><code># Reloading data
wowdata &lt;- read.csv(&quot;C:/users/njare/Desktop/website/content/wowbgs.csv&quot;)
colnames(wowdata) &lt;- c(&quot;Battleground&quot;, &quot;Code&quot;, &quot;Faction&quot;, &quot;Class&quot;, 
    &quot;Num_mortal_kills&quot;, &quot;Num_deaths&quot;, &quot;Honorable_kills&quot;, &quot;Damage_done&quot;, 
    &quot;Healing_done&quot;, &quot;Honor_awarded&quot;, &quot;Win&quot;, &quot;Lose&quot;, &quot;Class_speciality&quot;, 
    &quot;Bonus_event&quot;)

# Model
mean(wowdata$Honorable_kills)  #26.42056 honorable kills</code></pre>
<pre><code>## [1] 26.42056</code></pre>
<pre class="r"><code>Honorable_kills_c &lt;- wowdata$Honorable_kills - mean(wowdata$Honorable_kills)
fit &lt;- lm(Honor_awarded ~ Faction * Honorable_kills_c, data = wowdata)
summary(fit)</code></pre>
<pre><code>## 
## Call:
## lm(formula = Honor_awarded ~ Faction * Honorable_kills_c, data = wowdata)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -480.69 -119.12  -32.31  104.00  865.82 
## 
## Coefficients:
##                                Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)                    444.1682     3.9795  111.61   &lt;2e-16 ***
## FactionHorde                   -68.6016     5.6101  -12.23   &lt;2e-16 ***
## Honorable_kills_c                9.4024     0.2471   38.06   &lt;2e-16 ***
## FactionHorde:Honorable_kills_c  -4.5285     0.3509  -12.90   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 168.1 on 3722 degrees of freedom
## Multiple R-squared:  0.3323, Adjusted R-squared:  0.3318 
## F-statistic: 617.4 on 3 and 3722 DF,  p-value: &lt; 2.2e-16</code></pre>
<pre class="r"><code># Interaction plot
wowdata %&gt;% ggplot(aes(Honorable_kills_c, Honor_awarded, group = Faction)) + 
    geom_point() + geom_smooth(method = &quot;lm&quot;, aes(color = Faction)) + 
    theme(legend.position = c(0.89, 0.145)) + xlab(&quot;Honorable Kills Centered&quot;) + 
    ylab(&quot;Honor Awarded&quot;)</code></pre>
<p><img src="/project2_files/figure-html/unnamed-chunk-4-1.png" width="768" style="display: block; margin: auto;" /></p>
<pre class="r"><code># Check Assumptions
resids &lt;- fit$residuals
fitvals &lt;- fit$fitted.values
ggplot() + geom_point(aes(fitvals, resids)) + geom_hline(yintercept = 0, 
    col = &quot;red&quot;)</code></pre>
<p><img src="/project2_files/figure-html/unnamed-chunk-4-2.png" width="768" style="display: block; margin: auto;" /></p>
<pre class="r"><code>bptest(fit)  #p-value of less than 0.05. Homoskedasticity is not met.</code></pre>
<pre><code>## 
##  studentized Breusch-Pagan test
## 
## data:  fit
## BP = 191.03, df = 3, p-value &lt; 2.2e-16</code></pre>
<pre class="r"><code>ggplot() + geom_histogram(aes(resids), bins = 20)</code></pre>
<p><img src="/project2_files/figure-html/unnamed-chunk-4-3.png" width="768" style="display: block; margin: auto;" /></p>
<pre class="r"><code>ggplot() + geom_qq(aes(sample = resids)) + geom_qq_line(aes(sample = resids), 
    color = &quot;red&quot;)</code></pre>
<p><img src="/project2_files/figure-html/unnamed-chunk-4-4.png" width="768" style="display: block; margin: auto;" /></p>
<pre class="r"><code>ks.test(resids, &quot;pnorm&quot;, sd = sd(resids))  #Normality assumption does not appear to be met either.</code></pre>
<pre><code>## 
##  One-sample Kolmogorov-Smirnov test
## 
## data:  resids
## D = 0.078271, p-value &lt; 2.2e-16
## alternative hypothesis: two-sided</code></pre>
<pre class="r"><code># Regression with robust standard errors
coeftest(fit, vcov = vcovHC(fit))</code></pre>
<pre><code>## 
## t test of coefficients:
## 
##                                 Estimate Std. Error t value  Pr(&gt;|t|)    
## (Intercept)                    444.16815    4.81150  92.314 &lt; 2.2e-16 ***
## FactionHorde                   -68.60165    5.89596 -11.635 &lt; 2.2e-16 ***
## Honorable_kills_c                9.40238    0.28524  32.963 &lt; 2.2e-16 ***
## FactionHorde:Honorable_kills_c  -4.52845    0.35299 -12.829 &lt; 2.2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code># Bootstrapped SEs
set.seed(348)
samp_distn &lt;- replicate(5000, {
    boot_dat &lt;- boot_dat &lt;- wowdata[sample(nrow(wowdata), replace = TRUE), 
        ]
    fit1 &lt;- lm(Honor_awarded ~ Faction * Honorable_kills_c, data = boot_dat)
    coef(fit1)
})
samp_distn %&gt;% t %&gt;% as.data.frame %&gt;% summarize_all(sd)</code></pre>
<pre><code>##   (Intercept) FactionHorde Honorable_kills_c FactionHorde:Honorable_kills_c
## 1    5.556563     6.704724         0.3447838                      0.4165813</code></pre>
<pre class="r"><code># Compare SEs
coeftest(fit)[, 1:4]  #Normal-theory SEs</code></pre>
<pre><code>##                                  Estimate Std. Error   t value      Pr(&gt;|t|)
## (Intercept)                    444.168150  3.9795109 111.61376  0.000000e+00
## FactionHorde                   -68.601647  5.6100546 -12.22834  9.660915e-34
## Honorable_kills_c                9.402382  0.2470545  38.05793 5.470746e-268
## FactionHorde:Honorable_kills_c  -4.528455  0.3509005 -12.90524  2.624355e-37</code></pre>
<pre class="r"><code>coeftest(fit, vcov = vcovHC(fit))[, 1:4]  #Robust SEs</code></pre>
<pre><code>##                                  Estimate Std. Error   t value      Pr(&gt;|t|)
## (Intercept)                    444.168150  4.8115008  92.31385  0.000000e+00
## FactionHorde                   -68.601647  5.8959626 -11.63536  9.226256e-31
## Honorable_kills_c                9.402382  0.2852432  32.96269 2.676213e-209
## FactionHorde:Honorable_kills_c  -4.528455  0.3529897 -12.82886  6.762487e-37</code></pre>
<p><em>Honorable kills = 0 does not have a reasonable interpretation because it means that the player was idle or threw the match and was not yet removed from the game, so by centering Honorable kills, I am able to yield the difference in honor awarded for Horde players at Honorable kills (centered) = 0 –&gt; Honorable kills = 26.42056. Predicted honor awarded to a player controlling for Faction and Honorable kills would be 444.1682 honor points. Holding Honorable kills constant, players earn 68.6016 less honor points for being Horde. Holding Faction constant, players earn 9.4024 more honor points per 1 unit increase in Honorable kills. The slope for Honor awarded for Horde and Alliance are significantly different.</em></p>
<p><em>A few tests were ran in order to check the assumptions of linearity, normality, and homoskedasticity. The graphs and the p-value from the BP test reveal that the assumption of linearity and homoskedasticity were not met and the null hypothesis of homoskedasticity was rejected. Additionally, after running a KS test, normality does not seem to be met either. Because the null hypothesis was rejected, a regression with robust standard errors was then computed with the function coeftest(). This resulted in changes in the t-values for the coefficients from 111.61, -12.23, 38.06, and -12.9 to 92.314, -11.635, 32.963, and -12.829, respectively. However, the p-values still remained less than 2.2e-16. Overall, the model explains for 33.18% of the variation in honor awarded per player.</em></p>
<p><strong>Note:</strong> <em>In this portion of the discussion, all values were rounded to 2 decimal points.</em></p>
<p><em>I then ran the same regression, but this time I computed the bootstrapped standard errors. Inititally, in the normal theory SEs, the values for the coefficients were found to be 3.98, 5.61, 0.25, and 0.35. These SEs were all (except for the interaction SE) found to increase after running the coeftest() function which yielded the robust SEs; the values for the coefficients were then found to be 4.81, 5.90, 0.29, and 0.35. The p-values were also found to increase from the normal theory SEs to the robust SEs, but the p-values were still less than 2.2e-16. Lastly, for the bootstrapped standard errors, I received the values 5.62, 6.66, 0.36, and 0.43. Comparing these bootstrapped SEs to the robust SEs, these values were found to be larger.</em></p>
<hr />
<p>###Performing a Logistic Regression:</p>
<p><em>I did not have a binary variable in my data, so I converted my categorical variable, Win, to a binary numeric and overwrote data with this new column name. Now, Lose = 0 and Win = 1. Additionally, there was a column for lose which contains the same information, so I just chose to remove it to make the data look cleaner.</em></p>
<p><em>I will now be performing a logistic regression model in order to predict whether a player will win or lose from the three explanatory variables, Honor awarded, Honorable kills, and Damage done.</em></p>
<pre class="r"><code># Preparing the data
wowdata[is.na(wowdata)] &lt;- 0
wowdata &lt;- wowdata %&gt;% dplyr::select(-Lose)

# Logistic regression model
fit2 &lt;- glm(Win ~ Honor_awarded + Honorable_kills + Damage_done, 
    data = wowdata, family = &quot;binomial&quot;)
coeftest(fit2)</code></pre>
<pre><code>## 
## z test of coefficients:
## 
##                    Estimate  Std. Error  z value  Pr(&gt;|z|)    
## (Intercept)     -9.1056e+00  3.4383e-01 -26.4829 &lt; 2.2e-16 ***
## Honor_awarded    2.5779e-02  1.0227e-03  25.2074 &lt; 2.2e-16 ***
## Honorable_kills  7.9271e-03  5.2213e-03   1.5182     0.129    
## Damage_done     -1.6038e-05  2.0285e-06  -7.9059  2.66e-15 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code># odds
coef(fit2) %&gt;% exp %&gt;% round(5) %&gt;% data.frame</code></pre>
<pre><code>##                       .
## (Intercept)     0.00011
## Honor_awarded   1.02611
## Honorable_kills 1.00796
## Damage_done     0.99998</code></pre>
<pre class="r"><code># Confusion Matrix
prob &lt;- predict(fit2, type = &quot;response&quot;)
table(predict = as.numeric(prob &gt; 0.5), truth = wowdata$Win) %&gt;% 
    addmargins</code></pre>
<pre><code>##        truth
## predict    0    1  Sum
##     0   1663  175 1838
##     1    174 1714 1888
##     Sum 1837 1889 3726</code></pre>
<pre class="r"><code>(1663 + 1714)/3726  #accuracy</code></pre>
<pre><code>## [1] 0.9063339</code></pre>
<pre class="r"><code>1714/1889  #TPR</code></pre>
<pre><code>## [1] 0.9073584</code></pre>
<pre class="r"><code>1663/1837  #TNR</code></pre>
<pre><code>## [1] 0.9052803</code></pre>
<pre class="r"><code>1714/1888  #PPV</code></pre>
<pre><code>## [1] 0.907839</code></pre>
<pre class="r"><code># ROC and AUC
ROCplot &lt;- ggplot(wowdata) + geom_roc(aes(d = Win, m = prob), 
    n.cuts = 0) + geom_segment(aes(x = 0, xend = 1, y = 0, yend = 1), 
    lty = 2)
ROCplot</code></pre>
<p><img src="/project2_files/figure-html/unnamed-chunk-5-1.png" width="768" style="display: block; margin: auto;" /></p>
<pre class="r"><code>calc_auc(ROCplot)</code></pre>
<pre><code>##   PANEL group      AUC
## 1     1    -1 0.972713</code></pre>
<pre class="r"><code># Plot density
wowdata$Win &lt;- as.factor(wowdata$Win)
wowdata$logit &lt;- predict(fit2, type = &quot;link&quot;)
wowdata %&gt;% ggplot() + geom_density(aes(logit, color = Win, fill = Win), 
    alpha = 0.4) + geom_vline(xintercept = 0) + xlab(&quot;predictor (logit)&quot;)</code></pre>
<p><img src="/project2_files/figure-html/unnamed-chunk-5-2.png" width="768" style="display: block; margin: auto;" /></p>
<pre class="r"><code># Class_diag
class_diag &lt;- function(probs, truth) {
    tab &lt;- table(factor(probs &gt; 0.5, levels = c(&quot;FALSE&quot;, &quot;TRUE&quot;)), 
        truth)
    acc = sum(diag(tab))/sum(tab)
    sens = tab[2, 2]/colSums(tab)[2]
    spec = tab[1, 1]/colSums(tab)[1]
    ppv = tab[2, 2]/rowSums(tab)[2]
    if (is.numeric(truth) == FALSE &amp; is.logical(truth) == FALSE) 
        truth &lt;- as.numeric(truth) - 1
    # CALCULATE EXACT AUC
    ord &lt;- order(probs, decreasing = TRUE)
    probs &lt;- probs[ord]
    truth &lt;- truth[ord]
    TPR = cumsum(truth)/max(1, sum(truth))
    FPR = cumsum(!truth)/max(1, sum(!truth))
    dup &lt;- c(probs[-1] &gt;= probs[-length(probs)], FALSE)
    TPR &lt;- c(0, TPR[!dup], 1)
    FPR &lt;- c(0, FPR[!dup], 1)
    n &lt;- length(TPR)
    auc &lt;- sum(((TPR[-1] + TPR[-n])/2) * (FPR[-1] - FPR[-n]))
    data.frame(acc, sens, spec, ppv, auc)
}

# 10-fold CV
set.seed(348)
k = 10
data1 &lt;- wowdata[sample(nrow(wowdata)), ]
folds &lt;- cut(seq(1:nrow(wowdata)), breaks = k, labels = F)
diags &lt;- NULL
for (i in 1:k) {
    train &lt;- data1[folds != i, ]
    test &lt;- data1[folds == i, ]
    truth &lt;- test$Win
    fit3 &lt;- glm(Win ~ Honor_awarded + Honorable_kills + Damage_done, 
        data = train, family = &quot;binomial&quot;)
    probs &lt;- predict(fit3, newdata = test, type = &quot;response&quot;)
    diags &lt;- rbind(diags, class_diag(probs, truth))
}
apply(diags, 2, mean)</code></pre>
<pre><code>##       acc      sens      spec       ppv       auc 
## 0.9060617 0.9079202 0.9034370 0.9073545 0.9725346</code></pre>
<p><em>After running the logistic regression model, it was found that honor awarded and damage done are decent predictors for whether a player will win or not (both of the p-values were less than 0.05); however, honorable kills by itself is not a good predictor of whether a player will win or lose. The predicted odds of winning a battleground when honor awarded = honorable kills = damage done = 0 is 0.00011. Holding honorable kills and damage done constant, going up 1 honor awarded multiplies the odds by a factor of 1.02611. Holding honor awarded and damage done constant, going up 1 honorable kill multiplies the odds by a factor of 1.00796. Holding honor awarded and honorable kills constant, going up 1 damage done multiplies the odds by a factor of 0.99998. It appears that an increase in both honor awarded and honorable kills increases one’s odds in winning; however, the same cannot be said for an increase for damage done. When computing the confusion matrix, the accuracy was found to be 0.906, the sensitivity (TPR) was found to be 0.907, the specificity (TNR) was found to be 0.905, and the recall (PPV) was found to be 0.908. After generating a ROC curve, I was able to calculate the AUC for this model. I received a value of 0.973, which is a great value and reveals that honor awarded, honorable kills, and damage done are good predictors for whether a player will win a battleground or not. I then performed a 10-fold CV. The average out-of-sample accuracy was found to be 0.907, the sensitivity was found to be 0.907, and the recall was found to be 0.909.</em></p>
<hr />
<p>###LASSO Regression:</p>
<p><em>I will be performing a LASSO regression on the binary variable Win and all of the other variables that I am focusing on will act as predictors.</em></p>
<pre class="r"><code># Preparing the data:
wowdata &lt;- wowdata %&gt;% dplyr::select(-1, -2, -4, -5, -6, -12, 
    -13, -14)

# Performing LASSO
fit4 &lt;- glm(Win ~ ., data = wowdata, family = &quot;binomial&quot;)
summary(fit4)</code></pre>
<pre><code>## 
## Call:
## glm(formula = Win ~ ., family = &quot;binomial&quot;, data = wowdata)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -3.8402  -0.0804   0.0000   0.0399   4.2230  
## 
## Coefficients:
##                   Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)     -1.506e+01  6.854e-01 -21.974  &lt; 2e-16 ***
## FactionHorde     5.136e+00  2.753e-01  18.656  &lt; 2e-16 ***
## Honorable_kills  9.099e-03  7.342e-03   1.239    0.215    
## Damage_done     -2.434e-05  3.097e-06  -7.858 3.91e-15 ***
## Healing_done    -1.454e-05  2.497e-06  -5.824 5.75e-09 ***
## Honor_awarded    3.602e-02  1.569e-03  22.961  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 5164.61  on 3725  degrees of freedom
## Residual deviance:  773.21  on 3720  degrees of freedom
## AIC: 785.21
## 
## Number of Fisher Scoring iterations: 8</code></pre>
<pre class="r"><code>y &lt;- as.matrix(wowdata$Win)
x &lt;- model.matrix(fit4)[, -1]
cv &lt;- cv.glmnet(x, y, family = &quot;binomial&quot;)
lasso &lt;- glmnet(x, y, family = &quot;binomial&quot;, lambda = cv$lambda.1se)
coef(lasso)</code></pre>
<pre><code>## 6 x 1 sparse Matrix of class &quot;dgCMatrix&quot;
##                            s0
## (Intercept)     -1.171785e+01
## FactionHorde     3.864568e+00
## Honorable_kills  .           
## Damage_done     -1.371873e-05
## Healing_done    -7.212819e-06
## Honor_awarded    2.781104e-02</code></pre>
<pre class="r"><code>pred &lt;- predict(lasso, type = &quot;response&quot;, x)
table(as.numeric(pred &gt; 0.5), y) %&gt;% addmargins</code></pre>
<pre><code>##      y
##          0    1  Sum
##   0   1774   62 1836
##   1     63 1827 1890
##   Sum 1837 1889 3726</code></pre>
<pre class="r"><code>class_diag(pred, wowdata$Win)</code></pre>
<pre><code>##        acc      sens     spec       ppv       auc
## 1 0.966452 0.9671784 0.965705 0.9666667 0.9922469</code></pre>
<pre class="r"><code>set.seed(348)
k = 10
data2 &lt;- wowdata[sample(nrow(wowdata)), ]
folds &lt;- cut(seq(1:nrow(wowdata)), breaks = k, labels = F)
diags &lt;- NULL
for (i in 1:k) {
    train &lt;- data2[folds != i, ]
    test &lt;- data2[folds == i, ]
    truth &lt;- test$Win
    fit5 &lt;- glm(Win ~ Faction + Damage_done + Healing_done + 
        Honor_awarded, data = train, family = &quot;binomial&quot;)
    probs &lt;- predict(fit5, newdata = test, type = &quot;response&quot;)
    preds &lt;- ifelse(probs &gt; 0.5, 1, 0)
    diags &lt;- rbind(diags, class_diag(probs, truth))
}
diags %&gt;% summarize_all(mean)</code></pre>
<pre><code>##         acc     sens      spec       ppv       auc
## 1 0.9669867 0.965561 0.9679816 0.9694684 0.9924442</code></pre>
<p><em>After running the LASSO, the variables that will be retained includes: Faction, Damage done, Healing done, and Honor awarded. These variables are the most important predictors of whether a player will Win their battleground or not. Honorable kills was not found to be significant. Using only the retained variables will allow me to get a model that makes accurate predictions. The accuracy was found to be 0.9669852, compared to the out-of-sample accuracy of my logistic regression was found to be 0.907. As one can see, this accuracy was significantly higher than the one previously found.</em></p>
<hr />
<pre><code>## R version 3.6.2 (2019-12-12)
## Platform: x86_64-w64-mingw32/x64 (64-bit)
## Running under: Windows 10 x64 (build 17763)
## 
## Matrix products: default
## 
## locale:
## [1] LC_COLLATE=English_United States.1252 
## [2] LC_CTYPE=English_United States.1252   
## [3] LC_MONETARY=English_United States.1252
## [4] LC_NUMERIC=C                          
## [5] LC_TIME=English_United States.1252    
## 
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
##  [1] glmnet_3.0-2    Matrix_1.2-18   plotROC_2.2.1   MASS_7.3-51.4  
##  [5] forcats_0.4.0   stringr_1.4.0   purrr_0.3.3     readr_1.3.1    
##  [9] tidyr_1.0.0     tibble_2.1.3    tidyverse_1.3.0 lmtest_0.9-37  
## [13] zoo_1.8-6       sandwich_2.5-1  dplyr_0.8.3     ggplot2_3.2.1  
## [17] knitr_1.26     
## 
## loaded via a namespace (and not attached):
##  [1] Rcpp_1.0.3       lubridate_1.7.4  lattice_0.20-38  utf8_1.1.4      
##  [5] assertthat_0.2.1 zeallot_0.1.0    digest_0.6.23    foreach_1.4.7   
##  [9] plyr_1.8.5       R6_2.4.1         cellranger_1.1.0 backports_1.1.5 
## [13] reprex_0.3.0     evaluate_0.14    httr_1.4.1       blogdown_0.17   
## [17] pillar_1.4.2     rlang_0.4.2      lazyeval_0.2.2   readxl_1.3.1    
## [21] rstudioapi_0.10  rmarkdown_2.0    labeling_0.3     munsell_0.5.0   
## [25] broom_0.5.3      compiler_3.6.2   modelr_0.1.5     xfun_0.11       
## [29] pkgconfig_2.0.3  shape_1.4.4      htmltools_0.4.0  tidyselect_0.2.5
## [33] bookdown_0.16    codetools_0.2-16 fansi_0.4.0      crayon_1.3.4    
## [37] dbplyr_1.4.2     withr_2.1.2      grid_3.6.2       nlme_3.1-142    
## [41] jsonlite_1.6     gtable_0.3.0     lifecycle_0.1.0  DBI_1.0.0       
## [45] magrittr_1.5     formatR_1.7      scales_1.1.0     cli_2.0.0       
## [49] stringi_1.4.3    farver_2.0.1     fs_1.3.1         xml2_1.2.2      
## [53] vctrs_0.2.0      generics_0.0.2   iterators_1.0.12 tools_3.6.2     
## [57] glue_1.3.1       hms_0.5.2        yaml_2.2.0       colorspace_1.4-1
## [61] rvest_0.3.5      haven_2.2.0</code></pre>
<pre><code>## [1] &quot;2019-12-15 00:32:18 CST&quot;</code></pre>
<pre><code>##           sysname           release           version          nodename 
##         &quot;Windows&quot;          &quot;10 x64&quot;     &quot;build 17763&quot; &quot;LAPTOP-C6CPOL32&quot; 
##           machine             login              user    effective_user 
##          &quot;x86-64&quot;           &quot;njare&quot;           &quot;njare&quot;           &quot;njare&quot;</code></pre>
</div>
